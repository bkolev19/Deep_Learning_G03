{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1 Training Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates random x and dx data for training. Each x/dx has dim 8. Need to create a dataset of 1000 samples.\n",
    "\n",
    "x = np.random.rand(1000, 8)\n",
    "dx = np.random.rand(1000, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from autoencoder import Autoencoder\n",
    "\n",
    "# External imports  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Params for Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'activation': 'sigmoid',\n",
    " 'batch_size': 1,\n",
    " 'coefficient_initialization': 'constant',\n",
    " 'coefficient_mask': np.array([[False,  True, False],\n",
    "       [False, False, False],\n",
    "       [False,  True, False],\n",
    "       [ True, False,  True],\n",
    "       [False,  True, False],\n",
    "       [ True, False,  True],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [ True, False,  True],\n",
    "       [False,  True, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False],\n",
    "       [False, False, False]]),\n",
    " 'coefficient_threshold': 0.1,\n",
    " 'epoch_size': 512000,\n",
    " 'include_sine': False,\n",
    " 'input_dim': 8,\n",
    " 'latent_dim': 2,\n",
    " 'learning_rate': 0.001,\n",
    " 'library_dim': 20,\n",
    " 'loss_weight_decoder': 1.0,\n",
    " 'loss_weight_sindy_regularization': 1e-05,\n",
    " 'loss_weight_sindy_x': 0.0001,\n",
    " 'loss_weight_sindy_z': 0.0,\n",
    " 'max_epochs': 10001,\n",
    " 'model_order': 1,\n",
    " 'poly_order': 3,\n",
    " 'print_frequency': 100,\n",
    " 'print_progress': True,\n",
    " 'refinement_epochs': 1001,\n",
    " 'sequential_thresholding': False,\n",
    " 'threshold_frequency': 500,\n",
    " 'widths': [4, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Autoencoder(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], dx[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example encoder definition\n",
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleEncoder, self).__init__()\n",
    "        self.layer1 = nn.Linear(8, 4)  # Example layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = SimpleEncoder()\n",
    "\n",
    "# Prepare the input tensor, setting requires_grad=True\n",
    "x = torch.randn(1, 8, requires_grad=True)\n",
    "\n",
    "# Forward pass to obtain the encoder's output\n",
    "output = encoder(x)\n",
    "\n",
    "# Now, compute the gradient of the output with respect to the input x\n",
    "grads = torch.autograd.grad(outputs=output, inputs=x, grad_outputs=torch.ones_like(output))\n",
    "\n",
    "# grads is a tuple of gradients for each input, in this case, just x\n",
    "print(grads[0])  # This will show the gradient of the encoder output w.r.t. x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
